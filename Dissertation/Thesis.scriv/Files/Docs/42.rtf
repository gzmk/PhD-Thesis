{\rtf1\ansi\ansicpg1252\cocoartf1187\cocoasubrtf400
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;}
{\colortbl;\red255\green255\blue255;\red230\green255\blue79;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sl480\slmult1\pardirnatural\qj

\f0\b\fs24 \cf0 Matching Physical and Rendered Gloss\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sl480\slmult1\pardirnatural\qj

\b0 \cf0 	We came up with a novel method to quantify the physical gloss levels we created. We took photos of the physical gloss stimuli under a known, real-world illumination and using a fitting  algorithm we fitted three parameters of Ward bi-directional distribution function (BRDF). We then used these parameters to set the gloss levels of computer-rendered stimuli (see next section). \
	A BRDF defines how light is reflected off of a surface. Ward BRDF {\field{\*\fldinst{HYPERLINK "scrivcmt://C04C4950-D394-4F78-B9C3-AC84FE6D17EE"}}{\fldrslt (Ward, 1992)}} has four parameters where \uc0\u961 \dn4 d \up0 determines diffuse reflectance, \uc0\u961 \dn4 s \up0 determines specular reflectance and \uc0\u945 \dn4 x \up0 and \uc0\u945 \dn4 y \up0 determine the spread (roughness) of the highlights. When objects have isotropic reflections, \uc0\u945 \dn4 x \up0 = \uc0\u945 \dn4 y\up0 . In our fitting procedure we used Ward BRDF because it is {\field{\*\fldinst{HYPERLINK "scrivcmt://295FF498-1D78-48EF-AD94-C5631E0654A8"}}{\fldrslt close to}} the physical truth and it has simple parameters which are easy to manipulate.\
\
	 
\i Determining the illumination field:
\i0  Using a SpheroCam HDR camera with 16mm fish-eye lens we captured a 360\'b0 panoramic, high dynamic range (HDR) image of a room. The aperture was set to f/5.6, shutter speed was 1/8 second and ISO speed was 200. The resolution of the image was 5396\'d72698. The room was well-lit using various sources of illumination like desk and floor lamps located in different places across the room. We chose an indoor location as we needed the light in the captured image to be constant over time. In an outdoor environment due to conditions like sun's motion or weather, the illumination might change over time. As we needed to photograph multiple objects under the exact same illumination, using an indoor location avoided this problem.   \
\
	
\i Photographing physical gloss stimuli:
\i0  After taking the photo of the room we placed each physical gloss stimulus (painted Ping-Pong ball) in the same room and photographed them one by one. By doing so the room acted as a light field for the painted balls. Each painted Ping-Pong ball was stuck on a tripod and the tripod was placed in the same exact location where the SpheroCam was when it took the photo of the room. This was done because we measured the exact illumination of the room from the viewpoint of the SpheroCam and to replicate this illumination we placed each Ping-Pong ball in the same location. SpheroCam was placed 27.5 cm away from the tripod with the stimulus. This distance ensured that the stimulus was in focus.  The stimulus on the tripod was 114.5cm from the floor which matched the distance from floor to the center of the SpheroCam lens. We photographed every stimulus using the same aperture and exposure settings as used in photographing the room. Instead of taking a full 360\'b0 photo, we only took a photo of the 30\'b0 slice which had the stimulus in it. All photos were high dynamic range.  \
\
	{\field{\*\fldinst{HYPERLINK "scrivcmt://DF92747A-44A1-4BEB-995C-13F8D633C6CD"}}{\fldrslt 
\i Generating rendered reference scenes:}} Before the fitting procedure we created a sample rendered scene that matched the photos we took of each stimulus. This sample rendered scene had to match the size and location of the stimulus in the photo and the highlights on the stimulus created by the illumination field. We rendered an initial scene where the room photo was the illumination field and there was a rendered sphere with an arbitrary size and position. The gloss of the sample rendered sphere was chosen manually to look as close to the photo as possible. This was done to provide us visual guidance when matching the size and location of the sphere in the render and the photo. We did not need the gloss level to be correctly matched at this point. All the renderings were done using RenderToolbox3 {\field{\*\fldinst{HYPERLINK "scrivcmt://6AB4BB38-1529-4059-837A-07AEF123CF05"}}{\fldrslt (cite)}} for MATLAB using Mitsuba renderer. We then ran an fminsearch with x-scale, y-scale, x-position and y-position were the four parameters to be fitted. In each iteration the algorithm created an affine transformation matrix with a set of four parameters, applied this matrix on the rendered sphere and calculated a pixel-wise sum of squared error between the sample render and the photo of a given gloss stimulus. The search converged when the four parameters that give the minimum error was found. For each gloss stimulus photo taken, we created a different sample scene as each photo had small differences in the position of the painted ball. For each set of best fitting parameters we visually checked whether the locations of the highlights on the render were centered on the locations of the highlights in the photos. As a result, we had a reference render for each gloss level that matched the photo of that gloss level\'92s physical stimulus.    \
\
	
\i Gloss fitting procedure: 
\i0 The reference renders generated in the previous step were in turn used to find the Ward BRDF parameters that match the gloss level of a given photo. First, we  converted all of our reference renders to grayscale and applied a circular mask to each render to discard the pixel information coming from the background. For a given gloss level, we ran a 2-D grid search where the two parameters of the grid were \uc0\u961 \dn4 s \up0 for specularity and \uc0\u945  for highlight spread. The diffuse parameter \u961 \dn4 d \up0 was always equal to 1-\uc0\u961 \dn4 s\up0 . {\field{\*\fldinst{HYPERLINK "scrivcmt://0D20484B-7A0B-481A-823B-563FAB628565"}}{\fldrslt (This was done to ensure that the renderer does not clip the rho_s+rho_d to be equal to 1)}}. As our objects had isotropic reflections \uc0\u945 {\field{\*\fldinst{HYPERLINK "scrivcmt://9E72B4D7-1819-4E53-A40F-109D5BB5AF86"}}{\fldrslt x}} and \uc0\u945 {\field{\*\fldinst{HYPERLINK "scrivcmt://48E137E0-1B0A-4080-9300-3194573C2356"}}{\fldrslt y}} were equal to \uc0\u945  at all times. In every iteration of the grid search the algorithm rendered a 5414\'d72707 panoramic image with a rendered sphere located in the illumination field.  The rendered sphere\'92s gloss level was determined by the parameters picked from the search grid.  The image was then converted to grayscale and a circular mask was applied to discard the pixels  outside of the sphere. Before we calculated the error, every iteration we normalized both the reference photo and the rendered image by the mean luminance of each image respectively.  In each iteration error was calculated as the pixel-wise sum of squared error between the reference photo and the rendered image of the sphere. The algorithm worked such that the grid shrunk 35% around the best fitting pair of parameters and restarted the search with a finer grid until the best fitting parameters were found. \
	We ran the gloss fitting for each gloss level separately. As a result, for each gloss level, we had three parameters (\uc0\u961 \dn4 s, \up0 \uc0\u961 \dn4 d = 1- \up0 \uc0\u961 \dn4 s \up0 and \uc0\u945 ) that matched the physical gloss level of the painted Ping-Pong balls to the Ward BRDF parameters of a rendered sphere with the same illumination.  However, these parameters were calculated on the normalized photo-render pairs so we first undid the normalization step. Each best fit parameter was multiplied by the ratio of mean luminance of photo and mean luminance of render to undo the normalization. To make the albedo of the surfaces the same, we averaged across all the diffuse parameter fits and used the resulting value for the diffuse component. We also fit a line through the best fit values of specular component to ensure\cb2  fill this part in\cb1 . \

\i 	\cb2 Should I show a table of the fit parameters?\
\cb1 	\cb2 Figure to show residuals}