{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf210
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;}
{\colortbl;\red255\green255\blue255;\red230\green255\blue79;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\sl480\slmult1\pardirnatural

\f0\b\fs24 \cf0 Software and Apparatus\
\
	
\b0 The experimental software was written in C++ using OpenHaptics API. The experiment was conducted using a visual-haptic setup which allows simultaneous presentation of visual and haptic stimuli that were matched in spatial location. The observers viewed the visual stimulus via a mirror that reflected the mounted monitor screen. Haptic information was presented via a Geomagic PHANToM force feedback device. The visual and haptic objects were matched in size and location creating the multisensory percept of touching and viewing the same object. Observers did not see their hand doing the haptic exploration but the location of their finger was indicated as a cursor on the image. The haptic device also acted as the input device for observer responses. The observers used a chin rest to maintain their head position.  \cb2 Add the monitor resolution and graphics card. }